{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VnVtERaF2DN",
        "outputId": "1f1d39aa-2acf-4e7c-e8f3-ddbea801c204"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.47.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: xformers==0.0.29.post3 in /usr/local/lib/python3.12/dist-packages (0.0.29.post3)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.12/dist-packages (0.22.1)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.12/dist-packages (3.4.0)\n",
            "Requirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.12/dist-packages (25.1.1)\n",
            "Requirement already satisfied: unsloth_zoo in /usr/local/lib/python3.12/dist-packages (2025.8.9)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (5.29.5)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.34.4)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (0.1.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.1.8)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: unsloth in /usr/local/lib/python3.12/dist-packages (2025.8.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton cut_cross_entropy unsloth_zoo\n",
        "!pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "!pip install --no-deps unsloth"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastVisionModel\n",
        "import torch"
      ],
      "metadata": {
        "id": "QTLnTu1KHaRa"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fourbit_models = [\n",
        "    \"unsloth/Llama-3.2-11B-Vision-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Qwen2-VL-7B-Instruct-bnb-4bit\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "sy9ChY_SMh63"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model , tokenizer = FastVisionModel.from_pretrained(\n",
        "    \"unsloth/Qwen2-VL-7B-Instruct\",\n",
        "    load_in_4bit=True,\n",
        "    use_gradient_checkpointing=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r113-raQM1sP",
        "outputId": "3bbcafb0-1783-49b2-96bc-6d4bc20c4d2c"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.8.10: Fast Qwen2_Vl patching. Transformers: 4.55.4.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<string>:37: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastVisionModel.get_peft_model(\n",
        "    model,\n",
        "    finetune_vision_layers=True,\n",
        "    finetune_language_layers=True,\n",
        "    finetune_attention_modules=True,\n",
        "    finetune_mlp_modules=True,\n",
        "\n",
        "    r = 16,\n",
        "    lora_alpha = 15,\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,\n",
        "    task_type = \"CAUSAL_LM\",\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "CYlqA48MM2vX"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"unsloth/LaTeX_OCR\" , split=\"train\")"
      ],
      "metadata": {
        "id": "X1YAMtiiM2tg"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m393ftAQM2oA",
        "outputId": "748c09ee-8eaa-4510-9ef5-0f84e9951538"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['image', 'text'],\n",
              "    num_rows: 68686\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6y23MZMmM2lp",
        "outputId": "6fc81613-414e-435b-93b4-1453d9cf46ed"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=160x40>,\n",
              " 'text': '{ \\\\frac { N } { M } } \\\\in { \\\\bf Z } , { \\\\frac { M } { P } } \\\\in { \\\\bf Z } , { \\\\frac { P } { Q } } \\\\in { \\\\bf Z }'}"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[5][\"image\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        },
        "id": "saZpCVMbM2jU",
        "outputId": "a2b11fa1-a621-46be-bc41-79201fd6011a"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=280x40>"
            ],
            "image/png": "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\n",
            "image/jpeg": "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\n"
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instruction  = \"Write the Latex Representation of the Image\""
      ],
      "metadata": {
        "id": "gRfKUnupUFRI"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_conversation(sample):\n",
        "  conversation = [\n",
        "      {\n",
        "          \"role\":\"user\",\n",
        "          \"content\":[\n",
        "              {\"type\":\"text\" , \"text\":instruction},\n",
        "              {\"type\":\"image\" , \"image\":sample[\"image\"]}\n",
        "          ]\n",
        "      },\n",
        "      {\n",
        "          \"role\":\"assistant\",\n",
        "          \"content\":[\n",
        "              {\"type\":\"text\" , \"text\":sample[\"text\"]}\n",
        "          ]\n",
        "      }\n",
        "  ]\n",
        "  return {\"messages\" : conversation}\n",
        "\n"
      ],
      "metadata": {
        "id": "EiWE4cq4M2gc"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_to_conversation(dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_omnKJzM2eD",
        "outputId": "848fe1ea-482d-487e-d76a-5a5541cd43e3"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [{'role': 'user',\n",
              "   'content': [{'type': 'text',\n",
              "     'text': 'Write the Latex Representation of the Image'},\n",
              "    {'type': 'image',\n",
              "     'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=160x40>}]},\n",
              "  {'role': 'assistant',\n",
              "   'content': [{'type': 'text',\n",
              "     'text': '{ \\\\frac { N } { M } } \\\\in { \\\\bf Z } , { \\\\frac { M } { P } } \\\\in { \\\\bf Z } , { \\\\frac { P } { Q } } \\\\in { \\\\bf Z }'}]}]}"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converted_dataset = [convert_to_conversation(sample) for sample in dataset]"
      ],
      "metadata": {
        "id": "iL9jVUOVUn9q"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converted_dataset[100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRm3FKO2U0Il",
        "outputId": "d9d3bb43-e3e0-4065-c704-d9abbc6d8745"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [{'role': 'user',\n",
              "   'content': [{'type': 'text',\n",
              "     'text': 'Write the Latex Representation of the Image'},\n",
              "    {'type': 'image',\n",
              "     'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=200x50>}]},\n",
              "  {'role': 'assistant',\n",
              "   'content': [{'type': 'text',\n",
              "     'text': 'g _ { \\\\Gamma \\\\Omega } = { \\\\frac { \\\\delta _ { \\\\Gamma \\\\Omega } [ c ^ { 2 } + ( \\\\omega _ { 1 } ) ^ { 2 } ] } { [ c ^ { 2 } + ( \\\\omega _ { 1 } ) ^ { 2 } + ( \\\\omega _ { 2 } ) ^ { 2 } ] ^ { 2 } } }'}]}]}"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FastVisionModel.for_inference(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUFtbahQVj2j",
        "outputId": "c8e814ce-6fb7-456d-eedf-b6a9b79c0c09"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModel(\n",
              "  (base_model): LoraModel(\n",
              "    (model): Qwen2VLForConditionalGeneration(\n",
              "      (model): Qwen2VLModel(\n",
              "        (visual): Qwen2VisionTransformerPretrainedModel(\n",
              "          (patch_embed): PatchEmbed(\n",
              "            (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)\n",
              "          )\n",
              "          (rotary_pos_emb): VisionRotaryEmbedding()\n",
              "          (blocks): ModuleList(\n",
              "            (0-18): 19 x Qwen2VLVisionBlock(\n",
              "              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (attn): VisionAttention(\n",
              "                (qkv): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=3840, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "              (mlp): VisionMlp(\n",
              "                (fc1): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=5120, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (act): QuickGELUActivation()\n",
              "                (fc2): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=5120, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (19): Qwen2VLVisionBlock(\n",
              "              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (attn): VisionAttention(\n",
              "                (qkv): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=3840, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "              (mlp): VisionMlp(\n",
              "                (fc1): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=1280, out_features=5120, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=5120, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (act): QuickGELUActivation()\n",
              "                (fc2): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=5120, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=5120, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (20-21): 2 x Qwen2VLVisionBlock(\n",
              "              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (attn): VisionAttention(\n",
              "                (qkv): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=3840, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "              (mlp): VisionMlp(\n",
              "                (fc1): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=5120, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (act): QuickGELUActivation()\n",
              "                (fc2): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=5120, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (22): Qwen2VLVisionBlock(\n",
              "              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (attn): VisionAttention(\n",
              "                (qkv): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=1280, out_features=3840, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=3840, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=1280, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "              (mlp): VisionMlp(\n",
              "                (fc1): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=5120, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (act): QuickGELUActivation()\n",
              "                (fc2): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=5120, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (23-28): 6 x Qwen2VLVisionBlock(\n",
              "              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (attn): VisionAttention(\n",
              "                (qkv): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=3840, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "              (mlp): VisionMlp(\n",
              "                (fc1): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=5120, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (act): QuickGELUActivation()\n",
              "                (fc2): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=5120, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (29): Qwen2VLVisionBlock(\n",
              "              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (attn): VisionAttention(\n",
              "                (qkv): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=3840, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "              (mlp): VisionMlp(\n",
              "                (fc1): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=1280, out_features=5120, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=5120, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (act): QuickGELUActivation()\n",
              "                (fc2): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=5120, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=5120, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (30-31): 2 x Qwen2VLVisionBlock(\n",
              "              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (attn): VisionAttention(\n",
              "                (qkv): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=3840, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "              (mlp): VisionMlp(\n",
              "                (fc1): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=5120, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (act): QuickGELUActivation()\n",
              "                (fc2): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=5120, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (merger): PatchMerger(\n",
              "            (ln_q): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Sequential(\n",
              "              (0): Linear(in_features=5120, out_features=5120, bias=True)\n",
              "              (1): GELU(approximate='none')\n",
              "              (2): Linear(in_features=5120, out_features=3584, bias=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (language_model): Qwen2VLTextModel(\n",
              "          (embed_tokens): Embedding(152064, 3584, padding_idx=151654)\n",
              "          (layers): ModuleList(\n",
              "            (0-27): 28 x Qwen2VLDecoderLayer(\n",
              "              (self_attn): Qwen2VLAttention(\n",
              "                (q_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (k_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (v_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (o_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (rotary_emb): Qwen2VLRotaryEmbedding()\n",
              "              )\n",
              "              (mlp): Qwen2MLP(\n",
              "                (gate_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=18944, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (up_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=18944, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (down_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=18944, out_features=3584, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=18944, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (act_fn): SiLU()\n",
              "              )\n",
              "              (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "              (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "            )\n",
              "          )\n",
              "          (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "          (rotary_emb): Qwen2VLRotaryEmbedding()\n",
              "        )\n",
              "      )\n",
              "      (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = dataset[1][\"image\"]\n",
        "messages = [\n",
        "      {\n",
        "          \"role\":\"user\",\n",
        "          \"content\":[\n",
        "              {\"type\":\"text\" , \"text\":instruction},\n",
        "              {\"type\":\"image\" , \"image\":image}\n",
        "          ]\n",
        "      },\n",
        "]"
      ],
      "metadata": {
        "id": "kZm9u1ZVVnTC"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "inputs = tokenizer(\n",
        "    image, input_text,\n",
        "    add_special_tokens=False,\n",
        "    return_tensors=\"pt\"\n",
        ").to(\"cuda\")\n"
      ],
      "metadata": {
        "id": "xR80Ga8eV-rr"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextStreamer\n",
        "\n",
        "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
        "\n",
        "_ = model.generate(\n",
        "    **inputs,\n",
        "    streamer=streamer,\n",
        "    max_new_tokens=128,\n",
        "    use_cache=True,\n",
        "    temperature=1.5,\n",
        "    min_p=0.1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JucXep5IV-mj",
        "outputId": "faa72317-3a20-45ed-ba59-006f7fe8eda6"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Latex representation of the image is:\n",
            "\n",
            "\\[ D_{\\mu}^A \\tilde{A}_{\\mu}^B = 0 \\]<|im_end|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import is_bf16_supported\n",
        "from unsloth.trainer import UnslothVisionDataCollator\n",
        "from trl import SFTTrainer , SFTConfig"
      ],
      "metadata": {
        "id": "eRx5dqsUV-kP"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FastVisionModel.for_inference(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06qrNKkmV-hp",
        "outputId": "52fd1c47-f80d-4a70-9f51-821b7e1fe6ed"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModel(\n",
              "  (base_model): LoraModel(\n",
              "    (model): Qwen2VLForConditionalGeneration(\n",
              "      (model): Qwen2VLModel(\n",
              "        (visual): Qwen2VisionTransformerPretrainedModel(\n",
              "          (patch_embed): PatchEmbed(\n",
              "            (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)\n",
              "          )\n",
              "          (rotary_pos_emb): VisionRotaryEmbedding()\n",
              "          (blocks): ModuleList(\n",
              "            (0-18): 19 x Qwen2VLVisionBlock(\n",
              "              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (attn): VisionAttention(\n",
              "                (qkv): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=3840, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "              (mlp): VisionMlp(\n",
              "                (fc1): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=5120, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (act): QuickGELUActivation()\n",
              "                (fc2): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=5120, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (19): Qwen2VLVisionBlock(\n",
              "              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (attn): VisionAttention(\n",
              "                (qkv): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=3840, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "              (mlp): VisionMlp(\n",
              "                (fc1): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=1280, out_features=5120, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=5120, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (act): QuickGELUActivation()\n",
              "                (fc2): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=5120, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=5120, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (20-21): 2 x Qwen2VLVisionBlock(\n",
              "              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (attn): VisionAttention(\n",
              "                (qkv): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=3840, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "              (mlp): VisionMlp(\n",
              "                (fc1): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=5120, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (act): QuickGELUActivation()\n",
              "                (fc2): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=5120, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (22): Qwen2VLVisionBlock(\n",
              "              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (attn): VisionAttention(\n",
              "                (qkv): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=1280, out_features=3840, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=3840, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=1280, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "              (mlp): VisionMlp(\n",
              "                (fc1): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=5120, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (act): QuickGELUActivation()\n",
              "                (fc2): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=5120, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (23-28): 6 x Qwen2VLVisionBlock(\n",
              "              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (attn): VisionAttention(\n",
              "                (qkv): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=3840, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "              (mlp): VisionMlp(\n",
              "                (fc1): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=5120, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (act): QuickGELUActivation()\n",
              "                (fc2): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=5120, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (29): Qwen2VLVisionBlock(\n",
              "              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (attn): VisionAttention(\n",
              "                (qkv): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=3840, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "              (mlp): VisionMlp(\n",
              "                (fc1): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=1280, out_features=5120, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=5120, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (act): QuickGELUActivation()\n",
              "                (fc2): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=5120, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=5120, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (30-31): 2 x Qwen2VLVisionBlock(\n",
              "              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (attn): VisionAttention(\n",
              "                (qkv): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=3840, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "              (mlp): VisionMlp(\n",
              "                (fc1): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=5120, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (act): QuickGELUActivation()\n",
              "                (fc2): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=5120, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (merger): PatchMerger(\n",
              "            (ln_q): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Sequential(\n",
              "              (0): Linear(in_features=5120, out_features=5120, bias=True)\n",
              "              (1): GELU(approximate='none')\n",
              "              (2): Linear(in_features=5120, out_features=3584, bias=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (language_model): Qwen2VLTextModel(\n",
              "          (embed_tokens): Embedding(152064, 3584, padding_idx=151654)\n",
              "          (layers): ModuleList(\n",
              "            (0-27): 28 x Qwen2VLDecoderLayer(\n",
              "              (self_attn): Qwen2VLAttention(\n",
              "                (q_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (k_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (v_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (o_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (rotary_emb): Qwen2VLRotaryEmbedding()\n",
              "              )\n",
              "              (mlp): Qwen2MLP(\n",
              "                (gate_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=18944, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (up_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=18944, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (down_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=18944, out_features=3584, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=18944, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (act_fn): SiLU()\n",
              "              )\n",
              "              (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "              (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "            )\n",
              "          )\n",
              "          (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "          (rotary_emb): Qwen2VLRotaryEmbedding()\n",
              "        )\n",
              "      )\n",
              "      (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    data_collator = UnslothVisionDataCollator(model, tokenizer),\n",
        "    train_dataset = converted_dataset,\n",
        "    args = SFTConfig(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 30,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bf16_supported(),\n",
        "        bf16 = is_bf16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"none\",\n",
        "        remove_unused_columns = False,\n",
        "        dataset_text_field = \"\",\n",
        "        dataset_kwargs = {\"skip_prepare_dataset\": True},\n",
        "        dataset_num_proc = 4,\n",
        "        max_seq_length = 2048,\n",
        "    ),\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7pCx4biV-e6",
        "outputId": "ae265eab-0034-40b5-9a4d-07bcaa856f22"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Model does not have a default image size - using 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gTkA6LCVV-cm",
        "outputId": "0fc7d40d-0ce0-428a-ff1e-e4ed8753217a"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 68,686 | Num Epochs = 1 | Total steps = 30\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 50,855,936 of 8,342,231,552 (0.61% trained)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [30/30 02:19, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>entropy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.235100</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.395900</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.490500</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.048800</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.969800</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.998600</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.831800</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.587500</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.397800</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.424500</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.334100</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.280200</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.230700</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.106700</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.205600</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.136800</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.102900</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.094700</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.087200</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.167800</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.182400</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.179000</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.151000</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.138300</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.177900</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.146900</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.087200</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.312000</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.096400</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.180100</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=30, training_loss=0.4259425265093644, metrics={'train_runtime': 144.9326, 'train_samples_per_second': 1.656, 'train_steps_per_second': 0.207, 'total_flos': 1661933681209344.0, 'train_loss': 0.4259425265093644, 'epoch': 0.0034941618379291267})"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FastVisionModel.for_inference(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPaK3mUZaKh7",
        "outputId": "918135a5-be35-4356-95b3-aa3fd0d172dc"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModel(\n",
              "  (base_model): LoraModel(\n",
              "    (model): Qwen2VLForConditionalGeneration(\n",
              "      (model): Qwen2VLModel(\n",
              "        (visual): Qwen2VisionTransformerPretrainedModel(\n",
              "          (patch_embed): PatchEmbed(\n",
              "            (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)\n",
              "          )\n",
              "          (rotary_pos_emb): VisionRotaryEmbedding()\n",
              "          (blocks): ModuleList(\n",
              "            (0-18): 19 x Qwen2VLVisionBlock(\n",
              "              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (attn): VisionAttention(\n",
              "                (qkv): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=3840, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "              (mlp): VisionMlp(\n",
              "                (fc1): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=5120, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (act): QuickGELUActivation()\n",
              "                (fc2): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=5120, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (19): Qwen2VLVisionBlock(\n",
              "              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (attn): VisionAttention(\n",
              "                (qkv): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=3840, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "              (mlp): VisionMlp(\n",
              "                (fc1): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=1280, out_features=5120, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=5120, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (act): QuickGELUActivation()\n",
              "                (fc2): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=5120, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=5120, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (20-21): 2 x Qwen2VLVisionBlock(\n",
              "              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (attn): VisionAttention(\n",
              "                (qkv): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=3840, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "              (mlp): VisionMlp(\n",
              "                (fc1): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=5120, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (act): QuickGELUActivation()\n",
              "                (fc2): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=5120, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (22): Qwen2VLVisionBlock(\n",
              "              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (attn): VisionAttention(\n",
              "                (qkv): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=1280, out_features=3840, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=3840, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=1280, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "              (mlp): VisionMlp(\n",
              "                (fc1): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=5120, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (act): QuickGELUActivation()\n",
              "                (fc2): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=5120, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (23-28): 6 x Qwen2VLVisionBlock(\n",
              "              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (attn): VisionAttention(\n",
              "                (qkv): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=3840, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "              (mlp): VisionMlp(\n",
              "                (fc1): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=5120, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (act): QuickGELUActivation()\n",
              "                (fc2): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=5120, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (29): Qwen2VLVisionBlock(\n",
              "              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (attn): VisionAttention(\n",
              "                (qkv): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=3840, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "              (mlp): VisionMlp(\n",
              "                (fc1): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=1280, out_features=5120, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=5120, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (act): QuickGELUActivation()\n",
              "                (fc2): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=5120, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=5120, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (30-31): 2 x Qwen2VLVisionBlock(\n",
              "              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "              (attn): VisionAttention(\n",
              "                (qkv): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=3840, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "              (mlp): VisionMlp(\n",
              "                (fc1): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=5120, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (act): QuickGELUActivation()\n",
              "                (fc2): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=5120, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (merger): PatchMerger(\n",
              "            (ln_q): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Sequential(\n",
              "              (0): Linear(in_features=5120, out_features=5120, bias=True)\n",
              "              (1): GELU(approximate='none')\n",
              "              (2): Linear(in_features=5120, out_features=3584, bias=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (language_model): Qwen2VLTextModel(\n",
              "          (embed_tokens): Embedding(152064, 3584, padding_idx=151654)\n",
              "          (layers): ModuleList(\n",
              "            (0-27): 28 x Qwen2VLDecoderLayer(\n",
              "              (self_attn): Qwen2VLAttention(\n",
              "                (q_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (k_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (v_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (o_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (rotary_emb): Qwen2VLRotaryEmbedding()\n",
              "              )\n",
              "              (mlp): Qwen2MLP(\n",
              "                (gate_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=18944, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (up_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=18944, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (down_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=18944, out_features=3584, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=18944, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (act_fn): SiLU()\n",
              "              )\n",
              "              (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "              (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "            )\n",
              "          )\n",
              "          (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "          (rotary_emb): Qwen2VLRotaryEmbedding()\n",
              "        )\n",
              "      )\n",
              "      (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = dataset[2][\"image\"]"
      ],
      "metadata": {
        "id": "b8hZj9tAaRQW"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = \"write the latex representation of the image.\""
      ],
      "metadata": {
        "id": "y4ULmEPbaV6i"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"image\", \"image\": image},  # <-- pass your image object/tensor here\n",
        "            {\"type\": \"text\", \"text\": instruction}\n",
        "        ]\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "t5B5-SwYaYof"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "inputs = tokenizer(\n",
        "    image, input_text,\n",
        "    add_special_tokens=False,\n",
        "    return_tensors=\"pt\"\n",
        ").to(\"cuda\")\n"
      ],
      "metadata": {
        "id": "iVVn3ZtAayAt"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "id": "Dhm1ccosdirU",
        "outputId": "5c72d021-e8a8-4cfe-e38b-f7267153e6d7"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=320x50>"
            ],
            "image/png": "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\n",
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAyAUADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD3+iq1/f22mWE17eSiK2gUvJIQSFUdScdhWYPF+hGGxmW/Vkv8/ZCI3PnY5O35eeOfpzQBuUVk6DrsevJfywQukNrey2iyMQRN5ZAZl9t24f8AATWtQAUUVkxeJdJm1dtLiu99yHaI7Y2KeYo3GPzMbd4GSVzkAHjigDWorOTXdMk1afSlvIzqEEXnPb87wmcbgMcjPcU7S9ZsNagefT7gTxI5jZgrABgcEcgcg8H0oAm1HULbStNudQvJBHbW0TSyueyqMmquhawdb0/7WdOv7A+YyGG+iEcnHfAJ4PY5rnPibIZtF0zRQpb+2NVtbNwoBPl797nBPI2oc9euO9dqOlAC0Vn3Gt6fbal/Z0s5+2fZ2uhCsbMxiU4LcA98DHXJqbT9RtNW06G/sJ0uLWdd0cqdGHrQBl2HiJ9U8SX+nWVkXs9Obybq9eTaPOKhvLRcHdgEbiSMZHWt6uO8Cf8AIQ8Y/wDYfl/9Ew12NABWZea5bWWsWOmSRXJmvHKRyLCfKB2O+C/TOI24GT045rTrmfEssq634eaOyvJ0tr1p5nggLqiGCVMkj/adeBz3oA6aijtRQAUVU1LU7PSLI3d7N5cQZUGFLFmYgKqqASxJIAAGTTNL1ey1iGWSzkZvJlMMqSRtG8bjBKsrAEHBB5HIIPQ0AXqKr3t9a6db/aLydIIdyoXkOFBY4GT25IrCsvFE9341vNEGm3YtYbaKVLrygEJYyZbdu5VtoC4HUNntQB0tFYq+K9GbUxp4uyZmna2DeS/lGYDJj8zGzfgdM57da2qACiq1rqFneyTx21zFLJA5SVFYFkYEjBHUdDVnNABRVe+vbfTbKa8u5PLt4V3SPgnaO5OO1UJfE2jwaRbarJeotjdMqwTbWxIW+7jjJz29aANeiqP9rWraqmmozvctB9oZVU/u484Bb0ycgDqcH0NQw+INPutKudRs5HuYLZnWURRsXVk+8u0gHcPTrQBqUVVTUbOXS11KO4R7JofPWZTlTHjduHtjmud1Lxi1v4k0PT7GymvrTUN+65t0EiDHAw24D5Tkt146c0AdZWBa+JH/AOEsn8PahYm1nMTXFlMsm+O6iBAbHAKupPK88cgkVrTajZ297DZzXMcdxOCYo3YAvggHGevUVy2u/wDJUfCP/XpqP8oaAOyooooAKKKKACiiigDi/ilfrb+CrjTkuEiutWePT4dzAZ81wrnkjgKWJ7euKxNMtp3+Kmm6bc61Hfw6Jpsk0SpEkflyOREFwpOSEVuvIB/2q9NZFb7yg/UUBEByFUH1AoAr2Gn2ul2KWdjAsNvHnbGvQZJJ/Mkn8a8/fVvExkYi48QKCeAPD8fH/j9elUmB6CgDIj1KS08JtqV55xeC1aaXzofKc7VJOVGdp46Vw2gxx/8ACV+Hre11Y6nb2tjPeXUStGYLKVgoDgoB8zF5eHLHDMeOtejajp8Wp2TWk5YROylgpxkBg2PocYPsamit4IFdYYY4w7F2CKBuY9ScdSaAPJ9cldIJfiNpEaX11p2qzKY4Hz5toALdk4908wdcZJHBr0vw/pzaT4fsLF8GSGFRIR/E+MsfxYk/jWiqqowoA+gpelAHAa+x1P4xeFdOUhk060udRmTGR8w8pCR2wc4NdF4z1m48PeDdW1a0jWS4tbZ5I1YZG7HBI9BnJ+lYugw/2h8UvFGrNl1sobfTIXyCAdvmyAHHq6ZGeuc9q7ZlV1KsAykYIIyCKAPIdD8T6ZpnjDW7/VNfl1aWysobSGSNQ5lkJDSrGFGPmkaMKo7hh0XI1fBV3rGlweIdCOnww6mhOqafYTTEIsVxlhGWx/BJvUkcZ/OvQ0sbSMIEtoVCBQuIwNoXO0DjjGTj0zUhij8wy7F8zbt3Y5x1xn0oA5H4bLAfDdxP50kuoz3076n5qhXW63YdSoJACgKBg/dAPetS4u/FK3Mi2+kaTJCGPltJqcisy54JUQHB9sn61leBP+P/AMZf9h+X/wBEw1z3ivSlTxFGttqivq7alDqDXcoCHTLQYVlZ+6MRtVD94k8cE0AdbNqvii28vz9K0KLzHEab9YkXcx6AZg5PtVaLxJrdxftYw2vhuS8XdugXW3LjacN8vkZ4PB9K5jxvDc3Y1bVvKtZLXz4tJV5kZp4kZ0RzbgjaHLO3zc8ovPGBt6ZoWpJ47a+n0mK3062e5+yGK5UjMpBklZcbjI7AcZCqM8EnNAGwL7xac40bReOv/E2k4/8AIFU73xLremKrX9r4btVYEgz626AgdTzB0GR+dcnrtwNA8SS+PyJRp0d8+l38aJkSW21U345BKzhvc5x2q3eeEb1PCOlWml6LB9quYJRqNwkqQzRLMA0yJuXGWPy5I+ULwM4wAX/FWoXV3feGNK1Oay0yG8kmurm4imWQJ5O0xrHJIgAZiwO7AIwcetY+jardeHkuvFUt2kuk6vriW5e8IWV7UKIIplORk7lycglkG71r0mHTLabSbW0vLG3ZIo0HkOokVCFxgbuuOmaq6n4V0nWbqW41C3Nw0lo1oFkclI0bO4ovRWIOCw5wAKAMGa403VfiTdabrUtoxsbaI6fZXBH7xpA3mShW4cgKFGM7RnpurdmsTpepaprkYWRTp8USW6rg5hMrcH38wDpxiodX8HabrVjp1leNK8Ni8bIWCu7bMYy7KWB+XkqQTk810NAHi+mwS69b+E0t9X+0ahqN6mt6jBbqn2e2Vf3p+RR8jbzGvJyxLZPp0d14zurv4eardPeWtrqNlff2beXNsS0cOZljaZeSQBG+8Z6Hr0rtLnQ7GfT7qzji+yx3Q/etaHyXb1O5cHPv71Fp/hrStKup57C0S38+3jt3ij4jKR5C/L0yA2M+gAoAXQbLRbTTIm0GKzFo8ahJbYqwkUdCXGd31JJ5Ncnq914oPi/w8X0jSllH2ny1XUpCrfuxnJ8njj2P4V1Hhzw1ZeGLS4t7IsRcTm4lJREBcgKcKiqo4UdAO571oy2VtPd291LCjT2+7ynI5TcMNj6igCGSGe/0WSC+RLeaeFkkEEhkCEgj5WIGevoK4H4ZC58Q+G9AvL2J1s9Is1gtVYFRLOq7GkI7hFGxT6lz/dNemU2ONIkCRoqKOgUYAoA47RNQg06+8a6nq8kVstvqIEkrN92BbeIpnk/3icepNZXg7U7mLxzqIurGTT7PxHH/AGlYW8xIcNHiOTcP4XZfLk29geea7L+woRr0+ppJhbqFYrq3ZAyTFD+7fnowBI9wRnoKuX1o13bOkUvkTlGWO4VAzRZGCVz3oA8xtLzTVh8PaPqF7bQ6FLf6kwWZ8RzmG5KwQ7jwV+bdg9fLA56V302gQnVdHu7XyYILAzfuY4wAwkXHGOBzz+NJP4V02bwqnh1IxHYpEsSgxpKcD1DqwJPOSRnknrzWjpunwaVpdpp1tu8i1hSCPccnaoAGT34FAHI+BZdL1wXer3Elpc6691J9oU4aS0COyRxhT8yAKB6ZJLc5pPHbNBrvhq50wtJ4gWeWOztSP3c8TKPOEhyNqgBTuGSCBgHOK3j4XsG8WJ4jYE3qQtCmERQAcZywUM3T+IkDJxWRrv8AyVLwj/156h/KGgDr5ZkggeaVgkaKWZj0AAyTUOn6haarYQ31jOk9rOu+OVOjD1FWaOlABRRRQAUUUUAFFFFABRRRQAUUUUAFZ+uWF3qej3FpY6lLp104BiuolDGNgQeh4IOMEdwT0rQooAyfD2hroOnyQG5e6uJ55Lm5uHUKZZXbJOBwAOAB2AArWoooAKKKKAOb0nQr/RfE2qzwSwS6Tqk32t0clZYJ9qq2OCGVgoPJG3Henz+BvDNxrY1qXRrWTUhKs4uGBLb1xg9e2B+VdDRQBzWl+C9MtGt7u7hFzqEchuGkZ28vz2JLSCPO0Nkn5tueBXSModCpzgjBwcUtFAGXD4c0iHSJtJWxiawmLNJbyZdGLHLZDE9Tz9ea1KKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigArmYdB1C78bHXtUlgFvZwyW2nW0JLFVcqXldiB8x2gbRwAOpNdNRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAH/2Q==\n"
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextStreamer\n",
        "\n",
        "Text_streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
        "\n",
        "_ = model.generate(\n",
        "    **inputs,\n",
        "    streamer=Text_streamer,\n",
        "    max_new_tokens=128,\n",
        "    use_cache=True,\n",
        "    temperature=1.5,\n",
        "    min_p=0.1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seSMyfVOa8os",
        "outputId": "5ba99b12-cb3f-4136-edab-57041f40857f"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H ^ { \\prime } = \\beta N \\int d \\lambda \\left\\{ \\frac { 1 } { 2 \\beta ^ { 2 } N ^ { 2 } } \\partial _ { \\lambda } \\zeta ^ { \\dagger } \\partial _ { \\lambda } \\zeta + V ( \\lambda ) \\zeta ^ { \\dagger } \\zeta \\right\\} \\ .<|im_end|>\n"
          ]
        }
      ]
    }
  ]
}